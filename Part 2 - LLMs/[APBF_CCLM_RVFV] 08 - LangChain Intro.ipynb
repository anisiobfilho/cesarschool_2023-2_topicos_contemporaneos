{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centro de Estudos e Sistemas Avan√ßados do Recife\n",
    "\n",
    "P√≥s-gradua√ß√£o em Engenharia e An√°lise de Dados\n",
    "\n",
    "Disciplina de RNA e Deep Learning\n",
    "\n",
    "Professor: Silvan Ferreira da Silva Junior \n",
    " \n",
    "Grupo:\n",
    "* An√≠sio Pereira Batista Filho (apbf@cesar.school)\n",
    "* Carlos Cezar Lopes de Mendon√ßa (cclm@cesar.school)\n",
    "* Rodolpho Victor Fran√ßa Valsconcelos (rvfv@cesar.school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Ol√°! Como posso ajudar voc√™ hoje?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 8, 'total_tokens': 16}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5bd87c427a', 'finish_reason': 'stop', 'logprobs': None} id='run-131cada6-b4ac-4cc6-8d2d-f98a11d5c8f4-0' usage_metadata={'input_tokens': 8, 'output_tokens': 8, 'total_tokens': 16}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Ol√°\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Traduza o seguinte texto para portugu√™s: Artificial Intelligence is the future!')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Traduza o seguinte texto para portugu√™s: {texto}\")\n",
    "\n",
    "prompt = prompt_template.invoke({\"texto\": \"Artificial Intelligence is the future!\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A intelig√™ncia artificial √© o futuro!\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates de Mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Ol√°, como voc√™ est√°?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 36, 'total_tokens': 42}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None} id='run-c006a764-2219-45c2-b017-6eaee4658707-0' usage_metadata={'input_tokens': 36, 'output_tokens': 6, 'total_tokens': 42}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Voc√™ √© um tradutor de ingl√™s para portugu√™s. Traduza as mensagens que forem enviadas.\"),\n",
    "    HumanMessage(content=\"Hello, how are you?\"),\n",
    "]\n",
    "\n",
    "# messages = [\n",
    "#     (\"system\", \"Voc√™ √© um tradutor de ingl√™s para portugu√™s. Traduza as mensagens que forem enviadas.\"),\n",
    "#     (\"human\", \"Hello, how are you?\"),\n",
    "# ]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Voc√™ √© um tradutor de {lingua_origem} para {lingua_destino}. Traduza as mensagens que forem enviadas.\"),\n",
    "        (\"user\", \"{texto}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Voc√™ √© um tradutor de ingl√™s para portugu√™s. Traduza as mensagens que forem enviadas.'), HumanMessage(content='Hello, how are you?')]\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\n",
    "    \"lingua_origem\": \"ingl√™s\",\n",
    "    \"lingua_destino\": \"portugu√™s\",\n",
    "    \"texto\": \"Hello, how are you?\"\n",
    "})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ol√°, como voc√™ est√°?\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ol√°, como voc√™ est√°?\n"
     ]
    }
   ],
   "source": [
    "output = parser.invoke(response)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encadeamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Las playas de Recife tienen tiburones!\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"lingua_origem\": \"ingl√™s\",\n",
    "    \"lingua_destino\": \"espanhol\",\n",
    "    \"texto\": \"As praias de Recife tem tubar√µes!\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texto, lingua_origem, lingua_destino):\n",
    "    response = chain.invoke({\n",
    "        \"lingua_origem\": lingua_origem,\n",
    "        \"lingua_destino\": lingua_destino,\n",
    "        \"texto\": texto\n",
    "    })\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Las playas de Recife tienen tiburones!\n"
     ]
    }
   ],
   "source": [
    "output = translate(\"The beaches of Recife have sharks!\", \"ingl√™s\", \"espanhol\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exerc√≠cios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 1\n",
    "Crie uma `chain` que a partir de um t√≥pico informado pelo usu√°rio, crie uma piada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Por que o papagaio n√£o usa Facebook?\\n\\nPorque ele j√° tem muitos \"amigos\" e n√£o quer ser \"bloqueado\"! ü¶úüòÑ'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"Fa√ßa uma piada sobre {topico}\")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "chain.invoke({\"topico\" : \"papagaio\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 2\n",
    "Crie uma `chain` que classifique o sentimento de um texto de entrada em positivo, neutro ou negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O sentimento do texto \"Estou muito feliz hoje!\" √© positivo.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"Classifique o sentimento do seguinte texto em positivo, neutro ou negativo: {texto}\")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "response = chain.invoke({\"texto\": \"Estou muito feliz hoje!\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 3\n",
    "Crie uma `chain` que gere o c√≥digo de uma fun√ß√£o Python de acordo com a descri√ß√£o do usu√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Aqui est√° uma fun√ß√£o simples em Python que multiplica dois n√∫meros:\n",
      "\n",
      "```python\n",
      "def multiplicar(a, b):\n",
      "    return a * b\n",
      "\n",
      "# Exemplo de uso\n",
      "resultado = multiplicar(3, 4)\n",
      "print(f\"O resultado da multiplica√ß√£o √©: {resultado}\")\n",
      "```\n",
      "\n",
      "Nessa fun√ß√£o `multiplicar`, voc√™ passa dois argumentos, `a` e `b`, e ela retorna o resultado da multiplica√ß√£o desses dois n√∫meros. No exemplo, multiplicamos 3 por 4, resultando em 12. Voc√™ pode testar a fun√ß√£o com diferentes valores!\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Voc√™ √© um programador python s√™nior\"),\n",
    "        (\"user\", \"{texto}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "resultado = chain.invoke({\"texto\" : \"fa√ßa uma fun√ß√£o que multiplique 2 n√∫meros\"})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 4\n",
    "Crie uma `chain` que explique de forma simplificada um t√≥pico geral fornecido pelo usu√°rio e, em seguida, traduza a explica√ß√£o para ingl√™s. Utilize dois templates encadeados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) refers to the field of computer science that focuses on creating systems and algorithms capable of performing tasks that typically require human intelligence. This includes skills such as reasoning, learning, perception, natural language understanding, pattern recognition, and decision-making.\n",
      "\n",
      "AI can be divided into two main categories:\n",
      "\n",
      "1. **Weak AI (or Narrow AI)**: Systems designed to perform a specific task, such as virtual assistants (like Siri or Google Assistant), recommendation systems, or facial recognition tools. These systems are limited to their specific functions and do not possess consciousness or general understanding.\n",
      "\n",
      "2. **Strong AI (or General AI)**: A hypothetical form of artificial intelligence that would have the ability to understand, learn, and apply knowledge in a manner similar to a human across a wide range of tasks. This form of AI has not yet been achieved and is a topic of intense research and debate.\n",
      "\n",
      "AI employs techniques such as machine learning, neural networks, natural language processing, and optimization algorithms to enhance its performance and adaptability over time. With advancements in technology, AI has been applied in various fields, including medicine, finance, transportation, customer service, and entertainment, among others.\n"
     ]
    }
   ],
   "source": [
    "prompt_template_topico = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Voc√™ √© um especialista em conhecimentos gerais\"),\n",
    "        (\"user\", \"{topic}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_template_tradutor = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Voc√™ √© um tradutor\"),\n",
    "        (\"user\", \"{explanation}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain_1 = prompt_template_topico | llm | parser\n",
    "chain_2 = prompt_template_tradutor | llm | parser\n",
    "\n",
    "def explain_and_translate(topic):\n",
    "    explanation = chain_1.invoke({\"topic\": topic})\n",
    "\n",
    "    translation = chain_2.invoke({\"explanation\": explanation})\n",
    "\n",
    "    return translation\n",
    "\n",
    "# Exemplo de uso\n",
    "resultado = explain_and_translate(\"O que √© a intelig√™ncia artificial?\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 5 - Desafio\n",
    "Crie uma `chain` que responda perguntas sobre o CESAR School."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O CESAR School n√£o √© especificamente uma incubadora de empresas, mas faz parte do CESAR, que possui a CESAR.labs, uma incubadora e aceleradora de startups. Dentro do CESAR.labs, diversas empresas foram incubadas e aceleradas, mas n√£o h√° uma lista espec√≠fica de empresas incubadas diretamente pela CESAR School.\n",
      "\n",
      "Algumas das empresas que se destacaram e foram incubadas ou aceleradas pelo CESAR.labs incluem:\n",
      "\n",
      "1. Tempest Security Intelligence\n",
      "2. NeuroUp\n",
      "3. FusionTrak\n",
      "4. Pitang\n",
      "5. Radix.com\n",
      "\n",
      "Se voc√™ estiver interessado em informa√ß√µes espec√≠ficas sobre empresas incubadas ou projetos na CESAR School, recomendo consultar diretamente o site oficial do CESAR ou da CESAR School para obter informa√ß√µes mais detalhadas e atualizadas.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"O Centro de Estudos e Sistemas Avan√ßados do Recife, tamb√©m conhecido por seu acr√¥nimo CESAR, √© um centro de pesquisa e inova√ß√£o sem fins lucrativos com sede na cidade do Recife, Pernambuco e filiais em Sorocaba, Curitiba e Manaus.[1] O CESAR foi fundado em 1996 por tr√™s professores do Centro de Inform√°tica da UFPE, Silvio Meira, F√°bio Silva e Ismar Kaufman, como forma de aproximar a academia do mercado.Em 2019, o centro conta com mais de 600 funcion√°rios e em 2018 seu faturamento foi da ordem de R$ 100 milh√µes. O CESAR √© parte integrante e institui√ß√£o √¢ncora do Porto Digital, um dos maiores parques tecnol√≥gicos do Brasil tamb√©m sediado em Recife. Em 2010 o instituto ganhou o pr√™mio Finep de Inova√ß√£o na categoria de melhor institui√ß√£o brasileira de ci√™ncia e tecnologia. √Årea Educacional Al√©m de atuar como centro de pesquisa e inova√ß√£o, o CESAR criou um bra√ßo educacional, a CESAR School, oferecendo cursos de gradua√ß√£o, mestrados e doutorados profissionais. O centro iniciou sua atua√ß√£o na √°rea educacional em 2007 quando iniciou a oferta do mestrado profissional em Engenharia de Software, que foi avaliado pela CAPES em 2017 como um dos dois melhores mestrados profissionais na √°rea de computa√ß√£o do pa√≠s.[8] Em 2013 foi autorizada a abertura do segundo mestrado profissional, dessa vez com √™nfase em Design de Artefatos Digitais.[9] A partir de 2016 o mestrado em Design passou a tamb√©m ser oferecido na unidade de Manaus.[10] Em 2016 o Minist√©rio da Educa√ß√£o autorizou o CESAR a ofertar cursos de gradua√ß√£o[11] e come√ßaram a ser ofertados os cursos de Ci√™ncia da Computa√ß√£o e Design, com abertura da primeira turma no primeiro semestre de 2018.[12] A unidade de ensino superior usa a metodologia de aprendizagem baseada em problemas, que permite o contato com demandas reais da sociedade desde os primeiros dias do curso. Em 2019 o CESAR se tornou a primeira institui√ß√£o do pa√≠s a oferecer um curso de doutorado na modalidade profissional na √°rea de engenharia de software. Curso/Programa Gradua√ß√£o Ci√™ncia da Computa√ß√£o\tRecife\t[11] Design\tRecife\t[11] Mestrado Profissional Engenharia de Software\tRecife e Manaus\t[8][15] Design de Artefatos Digitais\tRecife e Manaus\t[16][15] Doutorado Profissional Engenharia de Software\tRecife\t[4][14] Empreendedorismo e CESAR.labs O instituto mant√©m uma incubadora de empresas e uma aceleradora, chamada CESAR.labs.[17] O CESAR.labs √© uma das aceleradoras parceiras do programa do governo federal Start-up Brasil,[18] tendo acelerado atrav√©s desse programa 12 empresas.[19] A aceleradora abre chamadas anualmente, investindo at√© R$ 200 mil por startup.[20] No total, o CESAR j√° contribuiu para a cria√ß√£o de mais de 50 novas empresas.[3]Empresas incubadas e aceleradas de destaque: Tempest Security Intelligence[21][22] NeuroUp[23] FusionTrak[24] Pitang[25] Radix.com[26] Unidades e Subsidi√°rias O CESAR possui quatro unidades, sendo sua sede no Recife e tr√™s filiais em Manaus, Curitiba e Sorocaba.[27] Al√©m das filiais, o instituto controla duas subsidi√°rias. O fundo de participa√ß√£o em empresas CESAR.PAR e a desenvolvedora de projetos de software Pitang.[25]\"),\n",
    "        (\"user\", \"{texto}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "resultado = chain.invoke({\"texto\" : \"Quais empresas encubadas no Cesar School?\"})\n",
    "\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
