{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centro de Estudos e Sistemas Avançados do Recife\n",
    "\n",
    "Pós-graduação em Engenharia e Análise de Dados\n",
    "\n",
    "Disciplina de RNA e Deep Learning\n",
    "\n",
    "Professor: Silvan Ferreira da Silva Junior \n",
    " \n",
    "Grupo:\n",
    "* Anísio Pereira Batista Filho (apbf@cesar.school)\n",
    "* Carlos Cezar Lopes de Mendonça (cclm@cesar.school)\n",
    "* Rodolpho Victor França Valsconcelos (rvfv@cesar.school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Olá! Como posso ajudar você hoje?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 8, 'total_tokens': 16}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_5bd87c427a', 'finish_reason': 'stop', 'logprobs': None} id='run-131cada6-b4ac-4cc6-8d2d-f98a11d5c8f4-0' usage_metadata={'input_tokens': 8, 'output_tokens': 8, 'total_tokens': 16}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Olá\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Traduza o seguinte texto para português: Artificial Intelligence is the future!')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Traduza o seguinte texto para português: {texto}\")\n",
    "\n",
    "prompt = prompt_template.invoke({\"texto\": \"Artificial Intelligence is the future!\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A inteligência artificial é o futuro!\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates de Mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Olá, como você está?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 36, 'total_tokens': 42}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None} id='run-c006a764-2219-45c2-b017-6eaee4658707-0' usage_metadata={'input_tokens': 36, 'output_tokens': 6, 'total_tokens': 42}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.\"),\n",
    "    HumanMessage(content=\"Hello, how are you?\"),\n",
    "]\n",
    "\n",
    "# messages = [\n",
    "#     (\"system\", \"Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.\"),\n",
    "#     (\"human\", \"Hello, how are you?\"),\n",
    "# ]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Você é um tradutor de {lingua_origem} para {lingua_destino}. Traduza as mensagens que forem enviadas.\"),\n",
    "        (\"user\", \"{texto}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.'), HumanMessage(content='Hello, how are you?')]\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\n",
    "    \"lingua_origem\": \"inglês\",\n",
    "    \"lingua_destino\": \"português\",\n",
    "    \"texto\": \"Hello, how are you?\"\n",
    "})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, como você está?\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, como você está?\n"
     ]
    }
   ],
   "source": [
    "output = parser.invoke(response)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encadeamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Las playas de Recife tienen tiburones!\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"lingua_origem\": \"inglês\",\n",
    "    \"lingua_destino\": \"espanhol\",\n",
    "    \"texto\": \"As praias de Recife tem tubarões!\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texto, lingua_origem, lingua_destino):\n",
    "    response = chain.invoke({\n",
    "        \"lingua_origem\": lingua_origem,\n",
    "        \"lingua_destino\": lingua_destino,\n",
    "        \"texto\": texto\n",
    "    })\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Las playas de Recife tienen tiburones!\n"
     ]
    }
   ],
   "source": [
    "output = translate(\"The beaches of Recife have sharks!\", \"inglês\", \"espanhol\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "Crie uma `chain` que a partir de um tópico informado pelo usuário, crie uma piada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Por que o papagaio não usa Facebook?\\n\\nPorque ele já tem muitos \"amigos\" e não quer ser \"bloqueado\"! 🦜😄'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"Faça uma piada sobre {topico}\")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "chain.invoke({\"topico\" : \"papagaio\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "Crie uma `chain` que classifique o sentimento de um texto de entrada em positivo, neutro ou negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O sentimento do texto \"Estou muito feliz hoje!\" é positivo.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"Classifique o sentimento do seguinte texto em positivo, neutro ou negativo: {texto}\")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "response = chain.invoke({\"texto\": \"Estou muito feliz hoje!\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3\n",
    "Crie uma `chain` que gere o código de uma função Python de acordo com a descrição do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Aqui está uma função simples em Python que multiplica dois números:\n",
      "\n",
      "```python\n",
      "def multiplicar(a, b):\n",
      "    return a * b\n",
      "\n",
      "# Exemplo de uso\n",
      "resultado = multiplicar(3, 4)\n",
      "print(f\"O resultado da multiplicação é: {resultado}\")\n",
      "```\n",
      "\n",
      "Nessa função `multiplicar`, você passa dois argumentos, `a` e `b`, e ela retorna o resultado da multiplicação desses dois números. No exemplo, multiplicamos 3 por 4, resultando em 12. Você pode testar a função com diferentes valores!\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Você é um programador python sênior\"),\n",
    "        (\"user\", \"{texto}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "resultado = chain.invoke({\"texto\" : \"faça uma função que multiplique 2 números\"})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4\n",
    "Crie uma `chain` que explique de forma simplificada um tópico geral fornecido pelo usuário e, em seguida, traduza a explicação para inglês. Utilize dois templates encadeados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) refers to the field of computer science that focuses on creating systems and algorithms capable of performing tasks that typically require human intelligence. This includes skills such as reasoning, learning, perception, natural language understanding, pattern recognition, and decision-making.\n",
      "\n",
      "AI can be divided into two main categories:\n",
      "\n",
      "1. **Weak AI (or Narrow AI)**: Systems designed to perform a specific task, such as virtual assistants (like Siri or Google Assistant), recommendation systems, or facial recognition tools. These systems are limited to their specific functions and do not possess consciousness or general understanding.\n",
      "\n",
      "2. **Strong AI (or General AI)**: A hypothetical form of artificial intelligence that would have the ability to understand, learn, and apply knowledge in a manner similar to a human across a wide range of tasks. This form of AI has not yet been achieved and is a topic of intense research and debate.\n",
      "\n",
      "AI employs techniques such as machine learning, neural networks, natural language processing, and optimization algorithms to enhance its performance and adaptability over time. With advancements in technology, AI has been applied in various fields, including medicine, finance, transportation, customer service, and entertainment, among others.\n"
     ]
    }
   ],
   "source": [
    "prompt_template_topico = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Você é um especialista em conhecimentos gerais\"),\n",
    "        (\"user\", \"{topic}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_template_tradutor = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Você é um tradutor\"),\n",
    "        (\"user\", \"{explanation}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain_1 = prompt_template_topico | llm | parser\n",
    "chain_2 = prompt_template_tradutor | llm | parser\n",
    "\n",
    "def explain_and_translate(topic):\n",
    "    explanation = chain_1.invoke({\"topic\": topic})\n",
    "\n",
    "    translation = chain_2.invoke({\"explanation\": explanation})\n",
    "\n",
    "    return translation\n",
    "\n",
    "# Exemplo de uso\n",
    "resultado = explain_and_translate(\"O que é a inteligência artificial?\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5 - Desafio\n",
    "Crie uma `chain` que responda perguntas sobre o CESAR School."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O CESAR School não é especificamente uma incubadora de empresas, mas faz parte do CESAR, que possui a CESAR.labs, uma incubadora e aceleradora de startups. Dentro do CESAR.labs, diversas empresas foram incubadas e aceleradas, mas não há uma lista específica de empresas incubadas diretamente pela CESAR School.\n",
      "\n",
      "Algumas das empresas que se destacaram e foram incubadas ou aceleradas pelo CESAR.labs incluem:\n",
      "\n",
      "1. Tempest Security Intelligence\n",
      "2. NeuroUp\n",
      "3. FusionTrak\n",
      "4. Pitang\n",
      "5. Radix.com\n",
      "\n",
      "Se você estiver interessado em informações específicas sobre empresas incubadas ou projetos na CESAR School, recomendo consultar diretamente o site oficial do CESAR ou da CESAR School para obter informações mais detalhadas e atualizadas.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"O Centro de Estudos e Sistemas Avançados do Recife, também conhecido por seu acrônimo CESAR, é um centro de pesquisa e inovação sem fins lucrativos com sede na cidade do Recife, Pernambuco e filiais em Sorocaba, Curitiba e Manaus.[1] O CESAR foi fundado em 1996 por três professores do Centro de Informática da UFPE, Silvio Meira, Fábio Silva e Ismar Kaufman, como forma de aproximar a academia do mercado.Em 2019, o centro conta com mais de 600 funcionários e em 2018 seu faturamento foi da ordem de R$ 100 milhões. O CESAR é parte integrante e instituição âncora do Porto Digital, um dos maiores parques tecnológicos do Brasil também sediado em Recife. Em 2010 o instituto ganhou o prêmio Finep de Inovação na categoria de melhor instituição brasileira de ciência e tecnologia. Área Educacional Além de atuar como centro de pesquisa e inovação, o CESAR criou um braço educacional, a CESAR School, oferecendo cursos de graduação, mestrados e doutorados profissionais. O centro iniciou sua atuação na área educacional em 2007 quando iniciou a oferta do mestrado profissional em Engenharia de Software, que foi avaliado pela CAPES em 2017 como um dos dois melhores mestrados profissionais na área de computação do país.[8] Em 2013 foi autorizada a abertura do segundo mestrado profissional, dessa vez com ênfase em Design de Artefatos Digitais.[9] A partir de 2016 o mestrado em Design passou a também ser oferecido na unidade de Manaus.[10] Em 2016 o Ministério da Educação autorizou o CESAR a ofertar cursos de graduação[11] e começaram a ser ofertados os cursos de Ciência da Computação e Design, com abertura da primeira turma no primeiro semestre de 2018.[12] A unidade de ensino superior usa a metodologia de aprendizagem baseada em problemas, que permite o contato com demandas reais da sociedade desde os primeiros dias do curso. Em 2019 o CESAR se tornou a primeira instituição do país a oferecer um curso de doutorado na modalidade profissional na área de engenharia de software. Curso/Programa Graduação Ciência da Computação\tRecife\t[11] Design\tRecife\t[11] Mestrado Profissional Engenharia de Software\tRecife e Manaus\t[8][15] Design de Artefatos Digitais\tRecife e Manaus\t[16][15] Doutorado Profissional Engenharia de Software\tRecife\t[4][14] Empreendedorismo e CESAR.labs O instituto mantém uma incubadora de empresas e uma aceleradora, chamada CESAR.labs.[17] O CESAR.labs é uma das aceleradoras parceiras do programa do governo federal Start-up Brasil,[18] tendo acelerado através desse programa 12 empresas.[19] A aceleradora abre chamadas anualmente, investindo até R$ 200 mil por startup.[20] No total, o CESAR já contribuiu para a criação de mais de 50 novas empresas.[3]Empresas incubadas e aceleradas de destaque: Tempest Security Intelligence[21][22] NeuroUp[23] FusionTrak[24] Pitang[25] Radix.com[26] Unidades e Subsidiárias O CESAR possui quatro unidades, sendo sua sede no Recife e três filiais em Manaus, Curitiba e Sorocaba.[27] Além das filiais, o instituto controla duas subsidiárias. O fundo de participação em empresas CESAR.PAR e a desenvolvedora de projetos de software Pitang.[25]\"),\n",
    "        (\"user\", \"{texto}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "resultado = chain.invoke({\"texto\" : \"Quais empresas encubadas no Cesar School?\"})\n",
    "\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
