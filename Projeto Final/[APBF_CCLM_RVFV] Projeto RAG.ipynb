{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Centro de Estudos e Sistemas Avançados do Recife\n",
        "\n",
        "Pós-graduação em Engenharia e Análise de Dados\n",
        "\n",
        "Disciplina de RNA e Deep Learning\n",
        "\n",
        "Professor: Silvan Ferreira da Silva Junior \n",
        " \n",
        "Grupo:\n",
        "* Anísio Pereira Batista Filho (apbf@cesar.school)\n",
        "* Carlos Cezar Lopes de Mendonça (cclm@cesar.school)\n",
        "* Rodolpho Victor França Valsconcelos (rvfv@cesar.school)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Construção de um RAG utilizando LangChain\n",
        "\n",
        "\n",
        "Deverá ser desenvolvido um sistema RAG (Retrieval-Augmented Generation) utilizando a biblioteca LangChain para um ou mais documentos de sua escolha. Podendo ser arquivos PDF, de texto, páginas da web etc. O projeto será avaliado nos seguintes aspectos:\n",
        "\n",
        "* Escolha do Documento\n",
        "* Splitting do Documento\n",
        "* Criação de Vector Store\n",
        "* Retrieval\n",
        "* Geração de Respostas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMMunM-1yCSb",
        "outputId": "38bf5e8e-8f7e-4e88-d141-118700c98de6"
      },
      "outputs": [],
      "source": [
        "# !pip install pymupdf langchain_community langchain_openai faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ahRDZvq2xsKc"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import fitz  # PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8vlAfq7x5zk",
        "outputId": "9ac4be34-b648-41b8-cac6-9ffd6f8afcdc"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqE9rHmbyYDB",
        "outputId": "459b1e7c-52aa-495b-95e3-7679052b4606"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "acwVYqRCxuHn"
      },
      "outputs": [],
      "source": [
        "def read_pdf(pdf_path):\n",
        "    pdf_text = ''\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        pdf_text += page.get_text()\n",
        "    return pdf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEXFXPg_xiSR",
        "outputId": "cf2fb2b5-bf51-4a47-bda6-3bcc3da35924"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\anisi\\anaconda3\\envs\\cesarschool310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n",
            "c:\\Users\\anisi\\anaconda3\\envs\\cesarschool310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O tópico principal do documento é o Guia do Scrum, que apresenta a definição, teoria, valores, papéis, eventos e artefatos do framework Scrum, visando ajudar pessoas, times e organizações a gerar valor por meio de soluções adaptativas para problemas complexos.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Leia e divida o documento PDF\n",
        "pdf_path = 'data/Scrum-Guide.pdf'\n",
        "text = read_pdf(pdf_path)\n",
        "\n",
        "# Divida o texto em blocos menores\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# Crie embeddings para os blocos de texto\n",
        "embeddings = OpenAIEmbeddings()  # Use seu modelo de embeddings aqui\n",
        "vector_store = FAISS.from_texts(texts, embeddings)\n",
        "\n",
        "# Configure o modelo de linguagem para gerar respostas\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Configure o sistema de recuperação e geração de respostas\n",
        "retriever = vector_store.as_retriever()\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",  # Pode ser \"map_reduce\" ou outro tipo suportado\n",
        "    retriever=retriever\n",
        ")\n",
        "\n",
        "# Função para responder perguntas\n",
        "def answer_question(question):\n",
        "    return qa_chain.run(question)\n",
        "\n",
        "# Teste do sistema\n",
        "question = \"Qual é o tópico principal do documento?\"\n",
        "answer = answer_question(question)\n",
        "print(answer)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
